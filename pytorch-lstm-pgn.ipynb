{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM Chess engine\n",
    "A totally nonsensical chess engine based off learning on PGN data.\n",
    "- No checks for legal moves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from pathlib import Path\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "sequence_length = 4\n",
    "batch_size = 200\n",
    "epochs = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, dataset):\n",
    "        super(Model, self).__init__()\n",
    "        self.lstm_size = 128\n",
    "        self.embedding_dim = 128\n",
    "        self.num_layers = 3\n",
    "\n",
    "        n_vocab = len(dataset.uniq_words)\n",
    "        self.embedding = nn.Embedding(\n",
    "            num_embeddings=n_vocab,\n",
    "            embedding_dim=self.embedding_dim,\n",
    "        )\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=self.lstm_size,\n",
    "            hidden_size=self.lstm_size,\n",
    "            num_layers=self.num_layers,\n",
    "            dropout=0.2,\n",
    "        )\n",
    "        self.fully_connected = nn.Linear(self.lstm_size, n_vocab)\n",
    "\n",
    "    def forward(self, x, prev_state):\n",
    "        embed = self.embedding(x)\n",
    "        output, state = self.lstm(embed, prev_state)\n",
    "        logits = self.fully_connected(output)\n",
    "        return logits, state\n",
    "\n",
    "    def init_state(self, sequence_length):\n",
    "        return (torch.zeros(self.num_layers, sequence_length, self.lstm_size),\n",
    "                torch.zeros(self.num_layers, sequence_length, self.lstm_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PGN parsing\n",
    "txt = Path(\"./datasets/pgn_small.txt\").read_text()\n",
    "games = txt.split(\"\\n\")\n",
    "clean_moves = []\n",
    "words = []\n",
    "c = 0\n",
    "for game in games:\n",
    "    if c >= 2000:\n",
    "        break\n",
    "        \n",
    "    if game == \"\":\n",
    "        continue\n",
    "    moves = re.split(\"\\d+\\.\", game)\n",
    "    \n",
    "    # Don't include short games\n",
    "    if len(moves) < 10:\n",
    "        continue\n",
    "        \n",
    "    c = c + 1\n",
    "    clean_moves = [m.strip() for m in moves if m != \"\"]\n",
    "    for move in clean_moves:\n",
    "        m = move.split(\" \")\n",
    "        words.append(m[0])\n",
    "        words.append(m[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, words):\n",
    "        self.sequence_length = sequence_length\n",
    "        self.batch_size = batch_size\n",
    "        self.words = words\n",
    "        self.uniq_words = self.get_uniq_words()\n",
    "        print(f\"unique words {len(self.uniq_words)}\")\n",
    "\n",
    "        self.index_to_word = {index: word for index, word in enumerate(self.uniq_words)}\n",
    "        self.word_to_index = {word: index for index, word in enumerate(self.uniq_words)}\n",
    "\n",
    "        self.words_indexes = [self.word_to_index[w] for w in self.words]\n",
    "\n",
    "\n",
    "    def get_uniq_words(self):\n",
    "        word_counts = Counter(self.words)\n",
    "        return sorted(word_counts, key=word_counts.get, reverse=True)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.words_indexes) - self.sequence_length\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return (\n",
    "            torch.tensor(self.words_indexes[index:index+self.sequence_length]),\n",
    "            torch.tensor(self.words_indexes[index+1:index+self.sequence_length+1]),\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataset, model, epochs):\n",
    "    model.train()\n",
    "\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.002)\n",
    "    \n",
    "    print(f\"Total batchs {len(dataloader)}\")\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        state_h, state_c = model.init_state(sequence_length)\n",
    "\n",
    "        for batch, (x, y) in enumerate(dataloader):\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            y_pred, (state_h, state_c) = model(x, (state_h, state_c))\n",
    "            loss = criterion(y_pred.transpose(1, 2), y)\n",
    "\n",
    "            state_h = state_h.detach()\n",
    "            state_c = state_c.detach()\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            if (batch + 1) % 20 == 0:\n",
    "                print({ 'epoch': epoch, 'batch': batch, 'loss': loss.item() })\n",
    "    print(\"All done!!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(dataset, model, text, next_words=1):\n",
    "    model.eval()\n",
    "\n",
    "    words = text.split(' ')\n",
    "    state_h, state_c = model.init_state(len(words))\n",
    "\n",
    "    for i in range(0, next_words):\n",
    "        x = torch.tensor([[dataset.word_to_index[w] for w in words[i:]]])\n",
    "        y_pred, (state_h, state_c) = model(x, (state_h, state_c))\n",
    "\n",
    "        last_word_logits = y_pred[0][-1]\n",
    "        p = torch.nn.functional.softmax(last_word_logits, dim=0).detach().numpy()\n",
    "        word_index = np.random.choice(len(last_word_logits), p=p)\n",
    "        words.append(dataset.index_to_word[word_index])\n",
    "\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unique words 2367\n",
      "Total batchs 676\n",
      "{'epoch': 0, 'batch': 19, 'loss': 6.350759983062744}\n",
      "{'epoch': 0, 'batch': 39, 'loss': 6.603416919708252}\n",
      "{'epoch': 0, 'batch': 59, 'loss': 6.2618865966796875}\n",
      "{'epoch': 0, 'batch': 79, 'loss': 6.656838893890381}\n",
      "{'epoch': 0, 'batch': 99, 'loss': 6.025484561920166}\n",
      "{'epoch': 0, 'batch': 119, 'loss': 6.6966938972473145}\n",
      "{'epoch': 0, 'batch': 139, 'loss': 6.281108379364014}\n",
      "{'epoch': 0, 'batch': 159, 'loss': 5.565322399139404}\n",
      "{'epoch': 0, 'batch': 179, 'loss': 6.430304050445557}\n",
      "{'epoch': 0, 'batch': 199, 'loss': 6.0007734298706055}\n",
      "{'epoch': 0, 'batch': 219, 'loss': 6.396431922912598}\n",
      "{'epoch': 0, 'batch': 239, 'loss': 5.893108367919922}\n",
      "{'epoch': 0, 'batch': 259, 'loss': 6.198031425476074}\n",
      "{'epoch': 0, 'batch': 279, 'loss': 5.9380693435668945}\n",
      "{'epoch': 0, 'batch': 299, 'loss': 6.046158313751221}\n",
      "{'epoch': 0, 'batch': 319, 'loss': 6.363229274749756}\n",
      "{'epoch': 0, 'batch': 339, 'loss': 6.018549919128418}\n",
      "{'epoch': 0, 'batch': 359, 'loss': 6.087062358856201}\n",
      "{'epoch': 0, 'batch': 379, 'loss': 5.961662769317627}\n",
      "{'epoch': 0, 'batch': 399, 'loss': 5.742735385894775}\n",
      "{'epoch': 0, 'batch': 419, 'loss': 6.104771137237549}\n",
      "{'epoch': 0, 'batch': 439, 'loss': 5.979989051818848}\n",
      "{'epoch': 0, 'batch': 459, 'loss': 5.999925136566162}\n",
      "{'epoch': 0, 'batch': 479, 'loss': 5.977164268493652}\n",
      "{'epoch': 0, 'batch': 499, 'loss': 6.0544586181640625}\n",
      "{'epoch': 0, 'batch': 519, 'loss': 6.072169780731201}\n",
      "{'epoch': 0, 'batch': 539, 'loss': 6.11229133605957}\n",
      "{'epoch': 0, 'batch': 559, 'loss': 5.9954352378845215}\n",
      "{'epoch': 0, 'batch': 579, 'loss': 6.280972480773926}\n",
      "{'epoch': 0, 'batch': 599, 'loss': 5.719143867492676}\n",
      "{'epoch': 0, 'batch': 619, 'loss': 6.0613179206848145}\n",
      "{'epoch': 0, 'batch': 639, 'loss': 6.1657328605651855}\n",
      "{'epoch': 0, 'batch': 659, 'loss': 6.166796684265137}\n",
      "{'epoch': 1, 'batch': 19, 'loss': 5.769174575805664}\n",
      "{'epoch': 1, 'batch': 39, 'loss': 6.081802845001221}\n",
      "{'epoch': 1, 'batch': 59, 'loss': 5.701076030731201}\n",
      "{'epoch': 1, 'batch': 79, 'loss': 6.236538887023926}\n",
      "{'epoch': 1, 'batch': 99, 'loss': 5.565662860870361}\n",
      "{'epoch': 1, 'batch': 119, 'loss': 6.350263595581055}\n",
      "{'epoch': 1, 'batch': 139, 'loss': 5.743873119354248}\n",
      "{'epoch': 1, 'batch': 159, 'loss': 5.058356285095215}\n",
      "{'epoch': 1, 'batch': 179, 'loss': 6.157589912414551}\n",
      "{'epoch': 1, 'batch': 199, 'loss': 5.624207019805908}\n",
      "{'epoch': 1, 'batch': 219, 'loss': 6.1646647453308105}\n",
      "{'epoch': 1, 'batch': 239, 'loss': 5.462759971618652}\n",
      "{'epoch': 1, 'batch': 259, 'loss': 5.7292280197143555}\n",
      "{'epoch': 1, 'batch': 279, 'loss': 5.561452865600586}\n",
      "{'epoch': 1, 'batch': 299, 'loss': 5.608262538909912}\n",
      "{'epoch': 1, 'batch': 319, 'loss': 6.044361114501953}\n",
      "{'epoch': 1, 'batch': 339, 'loss': 5.6078081130981445}\n",
      "{'epoch': 1, 'batch': 359, 'loss': 5.703763484954834}\n",
      "{'epoch': 1, 'batch': 379, 'loss': 5.497691631317139}\n",
      "{'epoch': 1, 'batch': 399, 'loss': 5.190813064575195}\n",
      "{'epoch': 1, 'batch': 419, 'loss': 5.662216663360596}\n",
      "{'epoch': 1, 'batch': 439, 'loss': 5.5397725105285645}\n",
      "{'epoch': 1, 'batch': 459, 'loss': 5.5491509437561035}\n",
      "{'epoch': 1, 'batch': 479, 'loss': 5.552375316619873}\n",
      "{'epoch': 1, 'batch': 499, 'loss': 5.725530624389648}\n",
      "{'epoch': 1, 'batch': 519, 'loss': 5.680973052978516}\n",
      "{'epoch': 1, 'batch': 539, 'loss': 5.6466875076293945}\n",
      "{'epoch': 1, 'batch': 559, 'loss': 5.599054336547852}\n",
      "{'epoch': 1, 'batch': 579, 'loss': 5.798835277557373}\n",
      "{'epoch': 1, 'batch': 599, 'loss': 5.2979655265808105}\n",
      "{'epoch': 1, 'batch': 619, 'loss': 5.6126909255981445}\n",
      "{'epoch': 1, 'batch': 639, 'loss': 5.690107345581055}\n",
      "{'epoch': 1, 'batch': 659, 'loss': 5.855098724365234}\n",
      "{'epoch': 2, 'batch': 19, 'loss': 5.351991653442383}\n",
      "{'epoch': 2, 'batch': 39, 'loss': 5.679179668426514}\n",
      "{'epoch': 2, 'batch': 59, 'loss': 5.171358108520508}\n",
      "{'epoch': 2, 'batch': 79, 'loss': 5.739399433135986}\n",
      "{'epoch': 2, 'batch': 99, 'loss': 5.000746250152588}\n",
      "{'epoch': 2, 'batch': 119, 'loss': 5.847462177276611}\n",
      "{'epoch': 2, 'batch': 139, 'loss': 5.305633068084717}\n",
      "{'epoch': 2, 'batch': 159, 'loss': 4.617624759674072}\n",
      "{'epoch': 2, 'batch': 179, 'loss': 5.8464226722717285}\n",
      "{'epoch': 2, 'batch': 199, 'loss': 5.175332069396973}\n",
      "{'epoch': 2, 'batch': 219, 'loss': 5.8069915771484375}\n",
      "{'epoch': 2, 'batch': 239, 'loss': 5.139232635498047}\n",
      "{'epoch': 2, 'batch': 259, 'loss': 5.485558032989502}\n",
      "{'epoch': 2, 'batch': 279, 'loss': 5.218684196472168}\n",
      "{'epoch': 2, 'batch': 299, 'loss': 5.328217029571533}\n",
      "{'epoch': 2, 'batch': 319, 'loss': 5.759212017059326}\n",
      "{'epoch': 2, 'batch': 339, 'loss': 5.3997392654418945}\n",
      "{'epoch': 2, 'batch': 359, 'loss': 5.427789688110352}\n",
      "{'epoch': 2, 'batch': 379, 'loss': 5.251077651977539}\n",
      "{'epoch': 2, 'batch': 399, 'loss': 4.828430652618408}\n",
      "{'epoch': 2, 'batch': 419, 'loss': 5.467133045196533}\n",
      "{'epoch': 2, 'batch': 439, 'loss': 5.305081844329834}\n",
      "{'epoch': 2, 'batch': 459, 'loss': 5.229192733764648}\n",
      "{'epoch': 2, 'batch': 479, 'loss': 5.313104629516602}\n",
      "{'epoch': 2, 'batch': 499, 'loss': 5.524945259094238}\n",
      "{'epoch': 2, 'batch': 519, 'loss': 5.458415985107422}\n",
      "{'epoch': 2, 'batch': 539, 'loss': 5.456008434295654}\n",
      "{'epoch': 2, 'batch': 559, 'loss': 5.356855869293213}\n",
      "{'epoch': 2, 'batch': 579, 'loss': 5.543987274169922}\n",
      "{'epoch': 2, 'batch': 599, 'loss': 5.126004695892334}\n",
      "{'epoch': 2, 'batch': 619, 'loss': 5.449315071105957}\n",
      "{'epoch': 2, 'batch': 639, 'loss': 5.454819202423096}\n",
      "{'epoch': 2, 'batch': 659, 'loss': 5.695222854614258}\n",
      "{'epoch': 3, 'batch': 19, 'loss': 5.198815822601318}\n",
      "{'epoch': 3, 'batch': 39, 'loss': 5.4412102699279785}\n",
      "{'epoch': 3, 'batch': 59, 'loss': 4.905887603759766}\n",
      "{'epoch': 3, 'batch': 79, 'loss': 5.54316520690918}\n",
      "{'epoch': 3, 'batch': 99, 'loss': 4.7264485359191895}\n",
      "{'epoch': 3, 'batch': 119, 'loss': 5.548290252685547}\n",
      "{'epoch': 3, 'batch': 139, 'loss': 5.108548164367676}\n",
      "{'epoch': 3, 'batch': 159, 'loss': 4.428745269775391}\n",
      "{'epoch': 3, 'batch': 179, 'loss': 5.660856246948242}\n",
      "{'epoch': 3, 'batch': 199, 'loss': 4.922314643859863}\n",
      "{'epoch': 3, 'batch': 219, 'loss': 5.577383518218994}\n",
      "{'epoch': 3, 'batch': 239, 'loss': 5.000077724456787}\n",
      "{'epoch': 3, 'batch': 259, 'loss': 5.308761119842529}\n",
      "{'epoch': 3, 'batch': 279, 'loss': 5.062605381011963}\n",
      "{'epoch': 3, 'batch': 299, 'loss': 5.069577693939209}\n",
      "{'epoch': 3, 'batch': 319, 'loss': 5.588922500610352}\n",
      "{'epoch': 3, 'batch': 339, 'loss': 5.214305877685547}\n",
      "{'epoch': 3, 'batch': 359, 'loss': 5.231651782989502}\n",
      "{'epoch': 3, 'batch': 379, 'loss': 5.058914661407471}\n",
      "{'epoch': 3, 'batch': 399, 'loss': 4.619344711303711}\n",
      "{'epoch': 3, 'batch': 419, 'loss': 5.333498001098633}\n",
      "{'epoch': 3, 'batch': 439, 'loss': 5.163354873657227}\n",
      "{'epoch': 3, 'batch': 459, 'loss': 5.020999908447266}\n",
      "{'epoch': 3, 'batch': 479, 'loss': 5.106531620025635}\n",
      "{'epoch': 3, 'batch': 499, 'loss': 5.365284442901611}\n",
      "{'epoch': 3, 'batch': 519, 'loss': 5.265863418579102}\n",
      "{'epoch': 3, 'batch': 539, 'loss': 5.258863925933838}\n",
      "{'epoch': 3, 'batch': 559, 'loss': 5.162765026092529}\n",
      "{'epoch': 3, 'batch': 579, 'loss': 5.399622917175293}\n",
      "{'epoch': 3, 'batch': 599, 'loss': 4.959212779998779}\n",
      "{'epoch': 3, 'batch': 619, 'loss': 5.28109884262085}\n",
      "{'epoch': 3, 'batch': 639, 'loss': 5.281655311584473}\n",
      "{'epoch': 3, 'batch': 659, 'loss': 5.526838302612305}\n",
      "{'epoch': 4, 'batch': 19, 'loss': 5.003620147705078}\n",
      "{'epoch': 4, 'batch': 39, 'loss': 5.313356876373291}\n",
      "{'epoch': 4, 'batch': 59, 'loss': 4.744146823883057}\n",
      "{'epoch': 4, 'batch': 79, 'loss': 5.41786003112793}\n",
      "{'epoch': 4, 'batch': 99, 'loss': 4.556061267852783}\n",
      "{'epoch': 4, 'batch': 119, 'loss': 5.446081161499023}\n",
      "{'epoch': 4, 'batch': 139, 'loss': 4.993745803833008}\n",
      "{'epoch': 4, 'batch': 159, 'loss': 4.271406173706055}\n",
      "{'epoch': 4, 'batch': 179, 'loss': 5.518840312957764}\n",
      "{'epoch': 4, 'batch': 199, 'loss': 4.694015979766846}\n",
      "{'epoch': 4, 'batch': 219, 'loss': 5.460571765899658}\n",
      "{'epoch': 4, 'batch': 239, 'loss': 4.904329299926758}\n",
      "{'epoch': 4, 'batch': 259, 'loss': 5.155514717102051}\n",
      "{'epoch': 4, 'batch': 279, 'loss': 4.953313827514648}\n",
      "{'epoch': 4, 'batch': 299, 'loss': 4.951970100402832}\n",
      "{'epoch': 4, 'batch': 319, 'loss': 5.4253106117248535}\n",
      "{'epoch': 4, 'batch': 339, 'loss': 5.052196502685547}\n",
      "{'epoch': 4, 'batch': 359, 'loss': 5.07072639465332}\n",
      "{'epoch': 4, 'batch': 379, 'loss': 4.884481906890869}\n",
      "{'epoch': 4, 'batch': 399, 'loss': 4.421640396118164}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 4, 'batch': 419, 'loss': 5.189685821533203}\n",
      "{'epoch': 4, 'batch': 439, 'loss': 5.065160751342773}\n",
      "{'epoch': 4, 'batch': 459, 'loss': 4.8421406745910645}\n",
      "{'epoch': 4, 'batch': 479, 'loss': 4.982901573181152}\n",
      "{'epoch': 4, 'batch': 499, 'loss': 5.232603549957275}\n",
      "{'epoch': 4, 'batch': 519, 'loss': 5.111843585968018}\n",
      "{'epoch': 4, 'batch': 539, 'loss': 5.08915901184082}\n",
      "{'epoch': 4, 'batch': 559, 'loss': 5.013657569885254}\n",
      "{'epoch': 4, 'batch': 579, 'loss': 5.232427597045898}\n",
      "{'epoch': 4, 'batch': 599, 'loss': 4.856278896331787}\n",
      "{'epoch': 4, 'batch': 619, 'loss': 5.163305759429932}\n",
      "{'epoch': 4, 'batch': 639, 'loss': 5.10181188583374}\n",
      "{'epoch': 4, 'batch': 659, 'loss': 5.398383617401123}\n",
      "{'epoch': 5, 'batch': 19, 'loss': 4.8831562995910645}\n",
      "{'epoch': 5, 'batch': 39, 'loss': 5.129215717315674}\n",
      "{'epoch': 5, 'batch': 59, 'loss': 4.617417812347412}\n",
      "{'epoch': 5, 'batch': 79, 'loss': 5.222854137420654}\n",
      "{'epoch': 5, 'batch': 99, 'loss': 4.365396022796631}\n",
      "{'epoch': 5, 'batch': 119, 'loss': 5.2408576011657715}\n",
      "{'epoch': 5, 'batch': 139, 'loss': 4.837311267852783}\n",
      "{'epoch': 5, 'batch': 159, 'loss': 4.098837852478027}\n",
      "{'epoch': 5, 'batch': 179, 'loss': 5.386998176574707}\n",
      "{'epoch': 5, 'batch': 199, 'loss': 4.511492729187012}\n",
      "{'epoch': 5, 'batch': 219, 'loss': 5.35151481628418}\n",
      "{'epoch': 5, 'batch': 239, 'loss': 4.801447868347168}\n",
      "{'epoch': 5, 'batch': 259, 'loss': 5.030580997467041}\n",
      "{'epoch': 5, 'batch': 279, 'loss': 4.856175422668457}\n",
      "{'epoch': 5, 'batch': 299, 'loss': 4.829298496246338}\n",
      "{'epoch': 5, 'batch': 319, 'loss': 5.294977188110352}\n",
      "{'epoch': 5, 'batch': 339, 'loss': 4.900420188903809}\n",
      "{'epoch': 5, 'batch': 359, 'loss': 4.947231292724609}\n",
      "{'epoch': 5, 'batch': 379, 'loss': 4.728285789489746}\n",
      "{'epoch': 5, 'batch': 399, 'loss': 4.2865190505981445}\n",
      "{'epoch': 5, 'batch': 419, 'loss': 5.066816329956055}\n",
      "{'epoch': 5, 'batch': 439, 'loss': 4.956621170043945}\n",
      "{'epoch': 5, 'batch': 459, 'loss': 4.691433429718018}\n",
      "{'epoch': 5, 'batch': 479, 'loss': 4.822385787963867}\n",
      "{'epoch': 5, 'batch': 499, 'loss': 5.063211917877197}\n",
      "{'epoch': 5, 'batch': 519, 'loss': 5.013857841491699}\n",
      "{'epoch': 5, 'batch': 539, 'loss': 4.936723709106445}\n",
      "{'epoch': 5, 'batch': 559, 'loss': 4.874239444732666}\n",
      "{'epoch': 5, 'batch': 579, 'loss': 5.116755485534668}\n",
      "{'epoch': 5, 'batch': 599, 'loss': 4.734879016876221}\n",
      "{'epoch': 5, 'batch': 619, 'loss': 5.038054943084717}\n",
      "{'epoch': 5, 'batch': 639, 'loss': 4.941802501678467}\n",
      "{'epoch': 5, 'batch': 659, 'loss': 5.291563510894775}\n",
      "All done!!!\n"
     ]
    }
   ],
   "source": [
    "dataset = Dataset(words)\n",
    "model = Model(dataset)\n",
    "train(dataset, model, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['e4', 'Nc3']\n"
     ]
    }
   ],
   "source": [
    "print(predict(dataset, model, text='e4'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
